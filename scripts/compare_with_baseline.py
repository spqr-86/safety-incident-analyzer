"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ç–µ–∫—É—â–∏—Ö –º–µ—Ç—Ä–∏–∫ —Å baseline.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python scripts/compare_with_baseline.py benchmarks/results_history.jsonl
    python scripts/compare_with_baseline.py --baseline benchmarks/baseline.json --current benchmarks/results_history.jsonl
"""

import json
import sys
from pathlib import Path
from typing import Dict, Any
import argparse
from datetime import datetime


def load_baseline(baseline_path: str) -> Dict[str, Any]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç baseline –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ JSON —Ñ–∞–π–ª–∞."""
    with open(baseline_path, "r", encoding="utf-8") as f:
        return json.load(f)


def load_latest_result(results_path: str) -> Dict[str, Any]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑ JSONL —Ñ–∞–π–ª–∞."""
    results = []
    with open(results_path, "r", encoding="utf-8") as f:
        for line in f:
            if line.strip():
                results.append(json.loads(line))

    if not results:
        raise ValueError(f"–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ {results_path}")

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–∞–º—ã–π –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    return results[-1]


def compare_metrics(baseline: Dict[str, Any], current: Dict[str, Any]) -> Dict[str, Any]:
    """
    –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ç–µ–∫—É—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏ —Å baseline.

    Returns:
        Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    """
    comparison = {
        "timestamp": current.get("timestamp", datetime.now().isoformat()),
        "baseline_date": baseline.get("date", "unknown"),
        "improvements": [],
        "regressions": [],
        "stable": [],
        "summary": {},
    }

    # –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    metrics_to_compare = [
        ("mean_correctness_score", "Correctness", 10.0, "higher_better"),
        ("mean_faithfulness_score", "Faithfulness", 1.0, "higher_better"),
        ("mean_answer_relevance_score", "Answer Relevance", 1.0, "higher_better"),
        ("citation_rate", "Citation Rate", 1.0, "higher_better"),
        ("p95_total_time", "P95 Latency", None, "lower_better"),
    ]

    baseline_metrics = baseline.get("metrics", {})
    current_metrics = current.get("aggregate_metrics", {})

    for metric_key, metric_name, max_value, direction in metrics_to_compare:
        baseline_value = baseline_metrics.get(metric_key, 0.0)
        current_value = current_metrics.get(metric_key, 0.0)

        # –í—ã—á–∏—Å–ª—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏–µ
        if baseline_value > 0:
            change_pct = ((current_value - baseline_value) / baseline_value) * 100
        else:
            change_pct = 0.0

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É–ª—É—á—à–µ–Ω–∏–µ –∏–ª–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏—é
        if direction == "higher_better":
            is_improvement = current_value > baseline_value
            is_regression = current_value < baseline_value * 0.95  # 5% –ø–æ—Ä–æ–≥
        else:  # lower_better
            is_improvement = current_value < baseline_value
            is_regression = current_value > baseline_value * 1.05  # 5% –ø–æ—Ä–æ–≥

        result = {
            "metric": metric_name,
            "baseline": baseline_value,
            "current": current_value,
            "change": current_value - baseline_value,
            "change_pct": change_pct,
            "direction": direction,
        }

        if is_improvement and abs(change_pct) > 1.0:  # –º–∏–Ω–∏–º—É–º 1% –∏–∑–º–µ–Ω–µ–Ω–∏–µ
            comparison["improvements"].append(result)
        elif is_regression:
            comparison["regressions"].append(result)
        else:
            comparison["stable"].append(result)

    # Summary
    comparison["summary"] = {
        "total_metrics": len(metrics_to_compare),
        "improvements": len(comparison["improvements"]),
        "regressions": len(comparison["regressions"]),
        "stable": len(comparison["stable"]),
        "overall_status": "‚úÖ IMPROVED" if len(comparison["improvements"]) > len(comparison["regressions"]) else (
            "‚ùå REGRESSED" if len(comparison["regressions"]) > 0 else "‚ûñ STABLE"
        ),
    }

    return comparison


def print_comparison(comparison: Dict[str, Any]) -> None:
    """–í—ã–≤–æ–¥–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –≤ –∫–æ–Ω—Å–æ–ª—å."""
    print("\n" + "=" * 70)
    print("üìä –°–†–ê–í–ù–ï–ù–ò–ï –° BASELINE")
    print("=" * 70)

    print(f"\nüìÖ Baseline –¥–∞—Ç–∞: {comparison['baseline_date']}")
    print(f"üìÖ –¢–µ–∫—É—â–∏–π –∑–∞–ø—É—Å–∫: {comparison['timestamp']}")

    print(f"\nüéØ –û–±—â–∏–π —Å—Ç–∞—Ç—É—Å: {comparison['summary']['overall_status']}")
    print(f"   –£–ª—É—á—à–µ–Ω–∏–π: {comparison['summary']['improvements']}")
    print(f"   –†–µ–≥—Ä–µ—Å—Å–∏–π: {comparison['summary']['regressions']}")
    print(f"   –°—Ç–∞–±–∏–ª—å–Ω–æ: {comparison['summary']['stable']}")

    # –£–ª—É—á—à–µ–Ω–∏—è
    if comparison["improvements"]:
        print("\n‚úÖ –£–õ–£–ß–®–ï–ù–ò–Ø:")
        for item in comparison["improvements"]:
            sign = "+" if item["change"] > 0 else ""
            print(f"   ‚Ä¢ {item['metric']}")
            print(f"     Baseline: {item['baseline']:.3f}")
            print(f"     –¢–µ–∫—É—â–µ–µ:  {item['current']:.3f}")
            print(f"     –ò–∑–º–µ–Ω–µ–Ω–∏–µ: {sign}{item['change']:.3f} ({sign}{item['change_pct']:.1f}%)")

    # –†–µ–≥—Ä–µ—Å—Å–∏–∏
    if comparison["regressions"]:
        print("\n‚ùå –†–ï–ì–†–ï–°–°–ò–ò:")
        for item in comparison["regressions"]:
            sign = "+" if item["change"] > 0 else ""
            print(f"   ‚Ä¢ {item['metric']}")
            print(f"     Baseline: {item['baseline']:.3f}")
            print(f"     –¢–µ–∫—É—â–µ–µ:  {item['current']:.3f}")
            print(f"     –ò–∑–º–µ–Ω–µ–Ω–∏–µ: {sign}{item['change']:.3f} ({sign}{item['change_pct']:.1f}%)")

    # –°—Ç–∞–±–∏–ª—å–Ω—ã–µ
    if comparison["stable"]:
        print("\n‚ûñ –°–¢–ê–ë–ò–õ–¨–ù–´–ï (–∏–∑–º–µ–Ω–µ–Ω–∏–µ < 1%):")
        for item in comparison["stable"]:
            print(f"   ‚Ä¢ {item['metric']}: {item['current']:.3f}")

    print("\n" + "=" * 70)


def save_comparison(comparison: Dict[str, Any], output_path: str) -> None:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –≤ JSON —Ñ–∞–π–ª."""
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(comparison, f, indent=2, ensure_ascii=False)
    print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_path}")


def main():
    parser = argparse.ArgumentParser(
        description="–°—Ä–∞–≤–Ω–∏—Ç—å —Ç–µ–∫—É—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏ —Å baseline"
    )
    parser.add_argument(
        "results",
        nargs="?",
        default="benchmarks/results_history.jsonl",
        help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ (JSONL)",
    )
    parser.add_argument(
        "--baseline",
        default="benchmarks/baseline.json",
        help="–ü—É—Ç—å –∫ baseline —Ñ–∞–π–ª—É (JSON)",
    )
    parser.add_argument(
        "--output",
        help="–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è",
    )

    args = parser.parse_args()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
    baseline_path = Path(args.baseline)
    results_path = Path(args.results)

    if not baseline_path.exists():
        print(f"‚ùå Baseline —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {baseline_path}")
        print("üí° –°–æ–∑–¥–∞–π—Ç–µ baseline —Ñ–∞–π–ª, –∑–∞–ø—É—Å—Ç–∏–≤: python eval/run_full_evaluation.py")
        sys.exit(1)

    if not results_path.exists():
        print(f"‚ùå –§–∞–π–ª —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {results_path}")
        print("üí° –ó–∞–ø—É—Å—Ç–∏—Ç–µ eval: python eval/run_full_evaluation.py")
        sys.exit(1)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    print("üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    baseline = load_baseline(str(baseline_path))
    current = load_latest_result(str(results_path))

    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º
    comparison = compare_metrics(baseline, current)

    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print_comparison(comparison)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω output
    if args.output:
        save_comparison(comparison, args.output)

    # Exit code –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    if comparison["summary"]["regressions"] > 0:
        print("\n‚ö†Ô∏è  –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –º–µ—Ç—Ä–∏–∫!")
        sys.exit(1)
    else:
        print("\n‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ –≤ –Ω–æ—Ä–º–µ –∏–ª–∏ —É–ª—É—á—à–∏–ª–∏—Å—å!")
        sys.exit(0)


if __name__ == "__main__":
    main()
