"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞.

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç LLM –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
–∏ –≤–∞—Ä–∏–∞—Ü–∏–π —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤.
"""

import os
import sys
import csv
from pathlib import Path
from typing import List, Dict
from dotenv import load_dotenv

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.append(str(Path(__file__).parent.parent))

from src.llm_factory import get_llm
from src.vector_store import load_vector_store
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import json

load_dotenv()


def generate_questions_from_context(context: str, llm, num_questions: int = 3) -> List[Dict[str, str]]:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≤–æ–ø—Ä–æ—Å—ã –∏ –æ—Ç–≤–µ—Ç—ã –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

    Args:
        context: –¢–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞/—á–∞–Ω–∫–∞
        llm: LLM –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        num_questions: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏

    Returns:
        –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏ –∏ –æ—Ç–≤–µ—Ç–∞–º–∏
    """
    prompt = ChatPromptTemplate.from_template(
        """–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é —Ç–µ—Å—Ç–æ–≤—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è —Å–∏—Å—Ç–µ–º—ã –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç –ø–æ –æ—Ö—Ä–∞–Ω–µ —Ç—Ä—É–¥–∞.

# –ó–ê–î–ê–ß–ê:
–ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –ö–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å–æ–∑–¥–∞–π {num_questions} –≤–æ–ø—Ä–æ—Å–∞ —Å —ç—Ç–∞–ª–æ–Ω–Ω—ã–º–∏ –æ—Ç–≤–µ—Ç–∞–º–∏.

# –¢–†–ï–ë–û–í–ê–ù–ò–Ø:
1. –í–æ–ø—Ä–æ—Å—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —á–µ—Ç–∫–∏–º–∏ –∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏
2. –û—Ç–≤–µ—Ç—ã –¥–æ–ª–∂–Ω—ã —Å—Ç—Ä–æ–≥–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –ö–æ–Ω—Ç–µ–∫—Å—Ç—É
3. –†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ: –ø—Ä–æ—Å—Ç—ã–µ —Ñ–∞–∫—Ç—ã, –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—è, –ø–µ—Ä–∏–æ–¥–∏—á–Ω–æ—Å—Ç—å, —É—Å–ª–æ–≤–∏—è –∏ —Ç.–¥.
4. –í–∫–ª—é—á–∏ –≤ –æ—Ç–≤–µ—Ç —Ü–∏—Ç–∞—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ [cite: X] (–º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å X=999 –∫–∞–∫ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä)
5. –í–æ–ø—Ä–æ—Å—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ (–∫–∞–∫ —Å–ø—Ä–æ—Å–∏–ª –±—ã —Ä–µ–∞–ª—å–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å)

# –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê:
–í–µ—Ä–Ω–∏ JSON-–º–∞—Å—Å–∏–≤ –æ–±—ä–µ–∫—Ç–æ–≤:
[
  {{
    "question": "–í–∞—à –≤–æ–ø—Ä–æ—Å?",
    "ground_truth": "–≠—Ç–∞–ª–æ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç —Å —Ñ–∞–∫—Ç–∞–º–∏ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ [cite: 999].",
    "difficulty": 1,  # 1=–ø—Ä–æ—Å—Ç–æ–π, 2=—Å—Ä–µ–¥–Ω–∏–π, 3=—Å–ª–æ–∂–Ω—ã–π
    "category": "–Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"
  }},
  ...
]

# –ö–û–ù–¢–ï–ö–°–¢:
{context}

JSON:"""
    )

    chain = prompt | llm | StrOutputParser()
    response = chain.invoke({"context": context, "num_questions": num_questions})

    try:
        questions = json.loads(response)
        return questions if isinstance(questions, list) else []
    except json.JSONDecodeError as e:
        print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
        print(f"–û—Ç–≤–µ—Ç LLM: {response}")
        return []


def generate_question_variations(
    original_question: str, original_answer: str, llm, num_variations: int = 2
) -> List[Dict[str, str]]:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞.

    Args:
        original_question: –ò—Å—Ö–æ–¥–Ω—ã–π –≤–æ–ø—Ä–æ—Å
        original_answer: –ò—Å—Ö–æ–¥–Ω—ã–π –æ—Ç–≤–µ—Ç
        llm: LLM
        num_variations: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞—Ä–∏–∞—Ü–∏–π

    Returns:
        –°–ø–∏—Å–æ–∫ –≤–∞—Ä–∏–∞—Ü–∏–π
    """
    prompt = ChatPromptTemplate.from_template(
        """–°–æ–∑–¥–∞–π {num_variations} –≤–∞—Ä–∏–∞—Ü–∏–∏ –≤–æ–ø—Ä–æ—Å–∞ —Å —Ä–∞–∑–Ω—ã–º–∏ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞–º–∏.

# –¢–†–ï–ë–û–í–ê–ù–ò–Ø:
1. –í–æ–ø—Ä–æ—Å—ã –¥–æ–ª–∂–Ω—ã —Å–ø—Ä–∞—à–∏–≤–∞—Ç—å –æ —Ç–æ–π –∂–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –Ω–æ –¥—Ä—É–≥–∏–º–∏ —Å–ª–æ–≤–∞–º–∏
2. –†–∞–∑–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (–ø—Ä—è–º–æ–π –≤–æ–ø—Ä–æ—Å, –∫–æ—Å–≤–µ–Ω–Ω—ã–π, —Å —É—Ç–æ—á–Ω–µ–Ω–∏–µ–º –∏ —Ç.–¥.)
3. –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –æ—Å—Ç–∞—Ç—å—Å—è —Ç–µ–º –∂–µ (–º–æ–∂–Ω–æ –Ω–µ–º–Ω–æ–≥–æ –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏)

# –û–†–ò–ì–ò–ù–ê–õ:
–í–æ–ø—Ä–æ—Å: {question}
–û—Ç–≤–µ—Ç: {answer}

# –§–û–†–ú–ê–¢:
–í–µ—Ä–Ω–∏ JSON: [{{"question": "...", "ground_truth": "...", "difficulty": 1, "category": "variation"}}]

JSON:"""
    )

    chain = prompt | llm | StrOutputParser()
    response = chain.invoke({
        "question": original_question,
        "answer": original_answer,
        "num_variations": num_variations,
    })

    try:
        variations = json.loads(response)
        return variations if isinstance(variations, list) else []
    except json.JSONDecodeError:
        print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤–∞—Ä–∏–∞—Ü–∏–π –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞: {original_question}")
        return []


def sample_documents_from_vectorstore(vector_store, num_samples: int = 10) -> List[str]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞.

    Args:
        vector_store: ChromaDB vector store
        num_samples: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

    Returns:
        –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    """
    # –ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    results = vector_store.similarity_search(
        "–æ—Ö—Ä–∞–Ω–∞ —Ç—Ä—É–¥–∞ –æ–±—É—á–µ–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ç–∞–∂", k=num_samples
    )
    return [doc.page_content for doc in results]


def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–æ–ø—Ä–æ—Å–æ–≤.
    """
    print("üöÄ –ó–∞–ø—É—Å–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–æ–ø—Ä–æ—Å–æ–≤...")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    llm = get_llm()
    vector_store = load_vector_store()

    # –ß–∏—Ç–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –¥–∞—Ç–∞—Å–µ—Ç
    dataset_path = Path(__file__).parent.parent / "tests" / "dataset.csv"
    existing_questions = []

    if dataset_path.exists():
        with open(dataset_path, "r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            existing_questions = list(reader)
        print(f"üìñ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(existing_questions)} —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤")

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
    new_questions = []

    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –í–∞—Ä–∏–∞—Ü–∏–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
    print("\nüîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∞—Ä–∏–∞—Ü–∏–π —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤...")
    for i, q_data in enumerate(existing_questions[:5], 1):  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 5 –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
        print(f"  –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–æ–ø—Ä–æ—Å–∞ {i}/5...")
        variations = generate_question_variations(
            q_data["question"].replace('[cite_start]', ''),
            q_data["ground_truth"],
            llm,
            num_variations=2,
        )
        new_questions.extend(variations)
        print(f"    ‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(variations)} –≤–∞—Ä–∏–∞—Ü–∏–π")

    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    print("\nüìÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
    documents = sample_documents_from_vectorstore(vector_store, num_samples=5)

    for i, doc in enumerate(documents, 1):
        print(f"  –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {i}/{len(documents)}...")
        # –ë–µ—Ä–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–ø–µ—Ä–≤—ã–µ 1000 —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
        context = doc[:1000]
        questions = generate_questions_from_context(context, llm, num_questions=2)
        new_questions.extend(questions)
        print(f"    ‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(questions)} –≤–æ–ø—Ä–æ—Å–æ–≤")

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –Ω–æ–≤—ã–π —Ñ–∞–π–ª
    output_path = Path(__file__).parent.parent / "tests" / "dataset_extended.csv"

    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ {len(new_questions)} –Ω–æ–≤—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –≤ {output_path}...")

    with open(output_path, "w", encoding="utf-8", newline="") as f:
        if new_questions:
            fieldnames = ["question", "ground_truth", "difficulty", "category"]
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(new_questions)

    print(f"‚úÖ –ì–æ—Ç–æ–≤–æ! –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(new_questions)} –≤–æ–ø—Ä–æ—Å–æ–≤")
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"  - –í–∞—Ä–∏–∞—Ü–∏–π —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö: ~{min(len(existing_questions) * 2, 10)}")
    print(f"  - –ò–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: ~{len(documents) * 2}")
    print(f"\nüí° –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
    print(f"  1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –≤ {output_path}")
    print(f"  2. –í—Ä—É—á–Ω—É—é –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ/—É–¥–∞–ª–∏—Ç–µ –Ω–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã")
    print(f"  3. –û–±—ä–µ–¥–∏–Ω–∏—Ç–µ —Å –æ—Å–Ω–æ–≤–Ω—ã–º –¥–∞—Ç–∞—Å–µ—Ç–æ–º: cat tests/dataset.csv tests/dataset_extended.csv > tests/dataset_full.csv")
    print(f"  4. –û–±–Ω–æ–≤–∏—Ç–µ run_ab_test.py –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –Ω–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞")


if __name__ == "__main__":
    main()
