"""
–ü–∞—Ä—Å–µ—Ä –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∑–æ–ª–æ—Ç–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –æ—Ç Perplexity –≤ CSV —Ñ–æ—Ä–º–∞—Ç.
–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤–æ–ø—Ä–æ—Å—ã –∏ –æ—Ç–≤–µ—Ç—ã –∏–∑ markdown —Å—Ç—Ä—É–∫—Ç—É—Ä—ã.
"""

import csv
import re
from pathlib import Path


def parse_perplexity_dataset(markdown_text: str) -> list[dict]:
    """
    –ü–∞—Ä—Å–∏—Ç markdown dataset –æ—Ç Perplexity –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç –ø–∞—Ä.
    """
    questions = []

    # –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤–æ–ø—Ä–æ—Å–æ–≤ (### Q1: ... ### Q25:)
    # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω: ### Q{number}: {question}
    question_pattern = r'### Q(\d+): (.+?)\n'

    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –≤–æ–ø—Ä–æ—Å—ã
    question_matches = list(re.finditer(question_pattern, markdown_text))

    for i, match in enumerate(question_matches):
        q_number = match.group(1)
        question_text = match.group(2).strip()

        # –ò—â–µ–º –æ—Ç–≤–µ—Ç –º–µ–∂–¥—É —Ç–µ–∫—É—â–∏–º –≤–æ–ø—Ä–æ—Å–æ–º –∏ —Å–ª–µ–¥—É—é—â–∏–º
        start_pos = match.end()

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω–µ—Ü –±–ª–æ–∫–∞ –≤–æ–ø—Ä–æ—Å–∞ (—Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –∫–æ–Ω–µ—Ü —É—Ä–æ–≤–Ω—è)
        if i + 1 < len(question_matches):
            end_pos = question_matches[i + 1].start()
        else:
            # –ü–æ—Å–ª–µ–¥–Ω–∏–π –≤–æ–ø—Ä–æ—Å - –∏—â–µ–º –∫–æ–Ω–µ—Ü —É—Ä–æ–≤–Ω—è –∏–ª–∏ —Å–µ–∫—Ü–∏–∏
            next_level = markdown_text.find('## –£–†–û–í–ï–ù–¨', start_pos)
            meta_section = markdown_text.find('## –ú–ï–¢–ê–ò–ù–§–û–†–ú–ê–¶–ò–Ø', start_pos)
            end_pos = min(x for x in [next_level, meta_section, len(markdown_text)] if x > start_pos)

        block = markdown_text[start_pos:end_pos]

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ç–≤–µ—Ç (–ø–æ—Å–ª–µ **–û—Ç–≤–µ—Ç**: –∏–ª–∏ **–û—Ç–≤–µ—Ç:**)
        answer_match = re.search(r'\*\*–û—Ç–≤–µ—Ç\*\*:\s*(.+?)(?=\n---|\n\n###|\Z)', block, re.DOTALL)

        if answer_match:
            answer_text = answer_match.group(1).strip()
            # –û—á–∏—â–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç –ª–∏—à–Ω–∏—Ö –ø–µ—Ä–µ–Ω–æ—Å–æ–≤ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            answer_text = re.sub(r'\n+', ' ', answer_text)
            answer_text = re.sub(r'\s+', ' ', answer_text)

            questions.append({
                'question': question_text,
                'ground_truth': answer_text
            })
            print(f"‚úÖ Q{q_number}: –ò–∑–≤–ª–µ—á–µ–Ω –≤–æ–ø—Ä–æ—Å –∏ –æ—Ç–≤–µ—Ç")
        else:
            print(f"‚ö†Ô∏è  Q{q_number}: –û—Ç–≤–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")

    return questions


def load_existing_dataset(csv_path: str) -> list[dict]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π CSV dataset."""
    questions = []
    with open(csv_path, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            questions.append({
                'question': row['question'],
                'ground_truth': row['ground_truth']
            })
    return questions


def check_duplicates(new_questions: list[dict], existing_questions: list[dict]) -> tuple[list[dict], list[str]]:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ —Ç–µ–∫—Å—Ç—É –≤–æ–ø—Ä–æ—Å–∞ (–Ω–µ—á–µ—Ç–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏ —Å–ø–∏—Å–æ–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤.
    """
    existing_questions_text = [q['question'].lower().strip() for q in existing_questions]

    unique_questions = []
    duplicates = []

    for new_q in new_questions:
        q_text_lower = new_q['question'].lower().strip()

        # –ù–µ—á–µ—Ç–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ (–ø–µ—Ä–≤—ã–µ 50 —Å–∏–º–≤–æ–ª–æ–≤)
        is_duplicate = False
        for existing_q_text in existing_questions_text:
            if q_text_lower[:50] == existing_q_text[:50]:
                is_duplicate = True
                duplicates.append(new_q['question'][:80] + '...')
                break

        if not is_duplicate:
            unique_questions.append(new_q)

    return unique_questions, duplicates


def save_merged_dataset(csv_path: str, all_questions: list[dict]):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π dataset."""
    with open(csv_path, 'w', encoding='utf-8', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=['question', 'ground_truth'])
        writer.writeheader()
        writer.writerows(all_questions)


def main():
    # –ü—É—Ç—å –∫ markdown —Ñ–∞–π–ª—É –æ—Ç Perplexity
    markdown_file = Path('perplexity_golden_dataset.md')

    if not markdown_file.exists():
        print(f"‚ùå –§–∞–π–ª {markdown_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        print("\n–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:")
        print("1. –°–æ—Ö—Ä–∞–Ω–∏—Ç–µ dataset –æ—Ç Perplexity –≤ —Ñ–∞–π–ª 'perplexity_golden_dataset.md'")
        print("2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç —Å–Ω–æ–≤–∞: python scripts/parse_perplexity_dataset.py")
        return

    # –ß–∏—Ç–∞–µ–º markdown
    with open(markdown_file, 'r', encoding='utf-8') as f:
        markdown_text = f.read()

    print("üîç –ü–∞—Ä—Å–∏–Ω–≥ –∑–æ–ª–æ—Ç–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –æ—Ç Perplexity...")
    print("=" * 70)

    # –ü–∞—Ä—Å–∏–º –≤–æ–ø—Ä–æ—Å—ã
    new_questions = parse_perplexity_dataset(markdown_text)

    print("\n" + "=" * 70)
    print(f"üìä –ò–∑–≤–ª–µ—á–µ–Ω–æ –≤–æ–ø—Ä–æ—Å–æ–≤: {len(new_questions)}")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π dataset
    existing_csv = Path('tests/dataset.csv')
    if existing_csv.exists():
        existing_questions = load_existing_dataset(str(existing_csv))
        print(f"üìÅ –°—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤: {len(existing_questions)}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        print("\nüîé –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã...")
        unique_questions, duplicates = check_duplicates(new_questions, existing_questions)

        if duplicates:
            print(f"‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {len(duplicates)}")
            for dup in duplicates[:5]:
                print(f"   - {dup}")
            if len(duplicates) > 5:
                print(f"   ... –∏ –µ—â–µ {len(duplicates) - 5}")
        else:
            print("‚úÖ –î—É–±–ª–∏–∫–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º
        all_questions = existing_questions + unique_questions
    else:
        print("‚ö†Ô∏è  –°—É—â–µ—Å—Ç–≤—É—é—â–∏–π dataset –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π")
        all_questions = new_questions

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ dataset ({len(all_questions)} –≤–æ–ø—Ä–æ—Å–æ–≤)...")
    save_merged_dataset(str(existing_csv), all_questions)

    print("\n" + "=" * 70)
    print("‚úÖ –ì–û–¢–û–í–û!")
    print(f"   –í—Å–µ–≥–æ –≤–æ–ø—Ä–æ—Å–æ–≤ –≤ dataset: {len(all_questions)}")
    print(f"   –ù–æ–≤—ã—Ö –¥–æ–±–∞–≤–ª–µ–Ω–æ: {len(new_questions) - len(duplicates) if existing_csv.exists() else len(new_questions)}")
    print(f"   –§–∞–π–ª: {existing_csv}")
    print("=" * 70)

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä
    if all_questions:
        print("\nüìù –ü—Ä–∏–º–µ—Ä –ø–µ—Ä–≤–æ–≥–æ –Ω–æ–≤–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞:")
        if existing_csv.exists():
            example = unique_questions[0] if unique_questions else new_questions[0]
        else:
            example = all_questions[0]
        print(f"   Q: {example['question'][:100]}...")
        print(f"   A: {example['ground_truth'][:150]}...")


if __name__ == '__main__':
    main()
