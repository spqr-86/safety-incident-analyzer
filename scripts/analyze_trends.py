"""
–ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ –º–µ—Ç—Ä–∏–∫ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –∑–∞–ø—É—Å–∫–æ–≤ eval.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python scripts/analyze_trends.py
    python scripts/analyze_trends.py --limit 10  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 –∑–∞–ø—É—Å–∫–æ–≤
    python scripts/analyze_trends.py --export benchmarks/trends.csv
"""

import json
import sys
import argparse
from pathlib import Path
from typing import List, Dict, Any
from datetime import datetime
import csv


def load_all_results(results_path: str, limit: int = None) -> List[Dict[str, Any]]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ JSONL —Ñ–∞–π–ª–∞."""
    results = []
    with open(results_path, "r", encoding="utf-8") as f:
        for line in f:
            if line.strip():
                results.append(json.loads(line))

    if limit:
        results = results[-limit:]

    return results


def calculate_trend(values: List[float]) -> Dict[str, Any]:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç —Ç—Ä–µ–Ω–¥ –¥–ª—è —Å–ø–∏—Å–∫–∞ –∑–Ω–∞—á–µ–Ω–∏–π.

    Returns:
        Dict —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ç—Ä–µ–Ω–¥–µ
    """
    if len(values) < 2:
        return {
            "direction": "insufficient_data",
            "change": 0.0,
            "change_pct": 0.0,
            "emoji": "‚ûñ",
        }

    first_value = values[0]
    last_value = values[-1]
    change = last_value - first_value

    if first_value != 0:
        change_pct = (change / first_value) * 100
    else:
        change_pct = 0.0

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
    if abs(change_pct) < 1.0:
        direction = "stable"
        emoji = "‚ûñ"
    elif change_pct > 0:
        direction = "improving"
        emoji = "üìà"
    else:
        direction = "declining"
        emoji = "üìâ"

    return {
        "direction": direction,
        "change": change,
        "change_pct": change_pct,
        "emoji": emoji,
        "first": first_value,
        "last": last_value,
        "min": min(values),
        "max": max(values),
        "avg": sum(values) / len(values),
    }


def analyze_metrics_trends(results: List[Dict[str, Any]]) -> Dict[str, Any]:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç—Ä–µ–Ω–¥—ã –¥–ª—è –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫."""
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã –¥–ª—è –∫–∞–∂–¥–æ–π –º–µ—Ç—Ä–∏–∫–∏
    metrics_timeseries = {}

    for result in results:
        timestamp = result.get("timestamp", "")
        metrics = result.get("aggregate_metrics", {})

        for metric_key, value in metrics.items():
            if metric_key not in metrics_timeseries:
                metrics_timeseries[metric_key] = {
                    "timestamps": [],
                    "values": [],
                }

            metrics_timeseries[metric_key]["timestamps"].append(timestamp)
            metrics_timeseries[metric_key]["values"].append(value)

    # –í—ã—á–∏—Å–ª—è–µ–º —Ç—Ä–µ–Ω–¥—ã
    trends = {}
    for metric_key, timeseries in metrics_timeseries.items():
        trends[metric_key] = calculate_trend(timeseries["values"])
        trends[metric_key]["timestamps"] = timeseries["timestamps"]
        trends[metric_key]["values"] = timeseries["values"]

    return trends


def print_trends_report(
    trends: Dict[str, Any],
    results_count: int,
    metric_names: Dict[str, str] = None,
) -> None:
    """–í—ã–≤–æ–¥–∏—Ç –æ—Ç—á–µ—Ç –ø–æ —Ç—Ä–µ–Ω–¥–∞–º."""
    if metric_names is None:
        metric_names = {
            "mean_correctness_score": "Correctness",
            "mean_faithfulness_score": "Faithfulness",
            "mean_answer_relevance_score": "Answer Relevance",
            "citation_rate": "Citation Rate",
            "p95_total_time": "P95 Latency",
            "mean_total_time": "Avg Latency",
        }

    print("\n" + "=" * 70)
    print("üìà –ê–ù–ê–õ–ò–ó –¢–†–ï–ù–î–û–í –ú–ï–¢–†–ò–ö")
    print("=" * 70)

    print(f"\nüìä –ê–Ω–∞–ª–∏–∑ –Ω–∞ –æ—Å–Ω–æ–≤–µ: {results_count} –∑–∞–ø—É—Å–∫–æ–≤ eval")

    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—é —Ç—Ä–µ–Ω–¥–∞
    improving = []
    declining = []
    stable = []

    for metric_key, trend_data in trends.items():
        metric_name = metric_names.get(metric_key, metric_key)

        if trend_data["direction"] == "improving":
            improving.append((metric_name, trend_data))
        elif trend_data["direction"] == "declining":
            declining.append((metric_name, trend_data))
        elif trend_data["direction"] == "stable":
            stable.append((metric_name, trend_data))

    # –£–ª—É—á—à–∞—é—â–∏–µ—Å—è –º–µ—Ç—Ä–∏–∫–∏
    if improving:
        print(f"\nüìà –£–õ–£–ß–®–ê–Æ–©–ò–ï–°–Ø –ú–ï–¢–†–ò–ö–ò ({len(improving)}):")
        for metric_name, trend in improving:
            print(f"\n   {trend['emoji']} {metric_name}")
            print(f"      –ü–µ—Ä–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ:  {trend['first']:.3f}")
            print(f"      –ü–æ—Å–ª–µ–¥–Ω–µ–µ:        {trend['last']:.3f}")
            print(f"      –ò–∑–º–µ–Ω–µ–Ω–∏–µ:        +{trend['change']:.3f} (+{trend['change_pct']:.1f}%)")
            print(f"      –ú–∏–Ω/–ú–∞–∫—Å/–°—Ä–µ–¥–Ω:   {trend['min']:.3f} / {trend['max']:.3f} / {trend['avg']:.3f}")

    # –£—Ö—É–¥—à–∞—é—â–∏–µ—Å—è –º–µ—Ç—Ä–∏–∫–∏
    if declining:
        print(f"\nüìâ –£–•–£–î–®–ê–Æ–©–ò–ï–°–Ø –ú–ï–¢–†–ò–ö–ò ({len(declining)}):")
        for metric_name, trend in declining:
            print(f"\n   {trend['emoji']} {metric_name}")
            print(f"      –ü–µ—Ä–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ:  {trend['first']:.3f}")
            print(f"      –ü–æ—Å–ª–µ–¥–Ω–µ–µ:        {trend['last']:.3f}")
            print(f"      –ò–∑–º–µ–Ω–µ–Ω–∏–µ:        {trend['change']:.3f} ({trend['change_pct']:.1f}%)")
            print(f"      –ú–∏–Ω/–ú–∞–∫—Å/–°—Ä–µ–¥–Ω:   {trend['min']:.3f} / {trend['max']:.3f} / {trend['avg']:.3f}")

    # –°—Ç–∞–±–∏–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    if stable:
        print(f"\n‚ûñ –°–¢–ê–ë–ò–õ–¨–ù–´–ï –ú–ï–¢–†–ò–ö–ò ({len(stable)}):")
        for metric_name, trend in stable:
            print(f"   ‚Ä¢ {metric_name}: {trend['avg']:.3f} (–≤–∞—Ä–∏–∞—Ü–∏—è: {abs(trend['change_pct']):.1f}%)")

    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    print("\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    if declining:
        print("   ‚ö†Ô∏è  –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —É—Ö—É–¥—à–∞—é—â–∏–µ—Å—è –º–µ—Ç—Ä–∏–∫–∏")
        print("   ‚Ä¢ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫–æ–¥–∞")
        print("   ‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–µ –∏–∑–º–µ–Ω–∏–ª–∏—Å—å –ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
        print("   ‚Ä¢ –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –æ—Ç–∫–∞—Ç –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –≤–µ—Ä—Å–∏–∏")
    elif improving:
        print("   ‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ —É–ª—É—á—à–∞—é—Ç—Å—è!")
        print("   ‚Ä¢ –ó–∞—Ñ–∏–∫—Å–∏—Ä—É–π—Ç–µ —Ç–µ–∫—É—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–∞–∫ baseline")
        print("   ‚Ä¢ –ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —Ç—Ä–µ–Ω–¥–∞")
    else:
        print("   ‚ûñ –ú–µ—Ç—Ä–∏–∫–∏ —Å—Ç–∞–±–∏–ª—å–Ω—ã")
        print("   ‚Ä¢ –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å –Ω–æ–≤—ã–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏")
        print("   ‚Ä¢ –ü—Ä–æ–≤–µ–¥–∏—Ç–µ hyperparameter optimization")

    print("\n" + "=" * 70)


def export_to_csv(trends: Dict[str, Any], output_path: str) -> None:
    """–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç —Ç—Ä–µ–Ω–¥—ã –≤ CSV."""
    # –ù–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫
    max_points = max(len(t["values"]) for t in trends.values())

    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    rows = []
    for i in range(max_points):
        row = {}
        for metric_key, trend_data in trends.items():
            if i < len(trend_data["values"]):
                row[f"{metric_key}"] = trend_data["values"][i]
                if i < len(trend_data["timestamps"]):
                    row["timestamp"] = trend_data["timestamps"][i]
        rows.append(row)

    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º CSV
    if rows:
        fieldnames = ["timestamp"] + list(trends.keys())
        with open(output_path, "w", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(rows)

        print(f"\nüíæ –î–∞–Ω–Ω—ã–µ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ CSV: {output_path}")
        print(f"   –°—Ç—Ä–æ–∫: {len(rows)}")
        print(f"   –ú–µ—Ç—Ä–∏–∫: {len(trends)}")


def main():
    parser = argparse.ArgumentParser(description="–ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ –º–µ—Ç—Ä–∏–∫")
    parser.add_argument(
        "--results",
        default="benchmarks/results_history.jsonl",
        help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏",
    )
    parser.add_argument(
        "--limit",
        type=int,
        help="–û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∑–∞–ø—É—Å–∫–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞",
    )
    parser.add_argument(
        "--export",
        help="–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ CSV",
    )

    args = parser.parse_args()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
    results_path = Path(args.results)
    if not results_path.exists():
        print(f"‚ùå –§–∞–π–ª —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {results_path}")
        print("üí° –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞: python eval/run_full_evaluation.py")
        sys.exit(1)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
    results = load_all_results(str(results_path), limit=args.limit)

    if len(results) < 2:
        print("‚ö†Ô∏è  –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤ (–Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 2 –∑–∞–ø—É—Å–∫–∞)")
        print(f"   –ù–∞–π–¥–µ–Ω–æ: {len(results)} –∑–∞–ø—É—Å–∫–æ–≤")
        sys.exit(1)

    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(results)} –∑–∞–ø—É—Å–∫–æ–≤")

    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç—Ä–µ–Ω–¥—ã
    print("üîç –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤...")
    trends = analyze_metrics_trends(results)

    # –í—ã–≤–æ–¥–∏–º –æ—Ç—á–µ—Ç
    print_trends_report(trends, len(results))

    # –≠–∫—Å–ø–æ—Ä—Ç –≤ CSV
    if args.export:
        export_to_csv(trends, args.export)


if __name__ == "__main__":
    main()
