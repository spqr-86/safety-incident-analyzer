# üöÄ Quick Start: Evaluation & Metrics

–ö—Ä–∞—Ç–∫–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞ —Ä–∞–±–æ—Ç—ã —Å eval —Å–∏—Å—Ç–µ–º–æ–π.

## üìã –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã (—á—Ç–æ –¥–µ–ª–∞—Ç—å –≤ –ø–µ—Ä–≤—É—é –æ—á–µ—Ä–µ–¥—å)

### ‚úÖ –≠—Ç–∞–ø 1: –ó–∞–ø—É—Å—Ç–∏—Ç—å baseline –æ—Ü–µ–Ω–∫—É (1-2 –¥–Ω—è)

**–¶–µ–ª—å:** –ü–æ–Ω—è—Ç—å —Ç–µ–∫—É—â–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ —Å–∏—Å—Ç–µ–º—ã

**–ó–∞–¥–∞—á–∏:**
1. –ó–∞–ø—É—Å—Ç–∏—Ç—å A/B —Ç–µ—Å—Ç –Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–º –¥–∞—Ç–∞—Å–µ—Ç–µ
2. –ó–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å baseline –º–µ—Ç—Ä–∏–∫–∏
3. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

**–ö–æ–º–∞–Ω–¥—ã:**
```bash
# 1. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –¥–∞—Ç–∞—Å–µ—Ç —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
cat tests/dataset.csv

# 2. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ LangSmith (–µ—Å–ª–∏ –µ—â–µ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ)
export LANGSMITH_API_KEY="your_key"
export LANGSMITH_PROJECT="safety-incident-analyzer"

# 3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ baseline eval
python run_ab_test.py

# 4. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ LangSmith UI
# https://smith.langchain.com/
```

**–û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:**
- Correctness score (0-10): —Ü–µ–ª–µ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ > 7.0
- QA score: —Ü–µ–ª–µ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ > 0.8
- Context QA score: —Ü–µ–ª–µ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ > 0.8

**–°–æ—Ö—Ä–∞–Ω–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:**
```bash
# –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª —Å baseline –º–µ—Ç—Ä–∏–∫–∞–º–∏
cat > benchmarks/baseline.json << 'EOF'
{
  "date": "2025-12-14",
  "dataset": "golden-questions",
  "dataset_size": 16,
  "metrics": {
    "correctness_score": 7.5,
    "qa_score": 0.85,
    "context_qa_score": 0.82
  },
  "config": {
    "llm": "gigachat",
    "embeddings": "openai/text-embedding-3-small",
    "chunk_size": 1200,
    "vector_search_k": 10
  }
}
EOF
```

---

### ‚úÖ –≠—Ç–∞–ø 2: –î–æ–±–∞–≤–∏—Ç—å retrieval –º–µ—Ç—Ä–∏–∫–∏ (2-3 –¥–Ω—è)

**–¶–µ–ª—å:** –û—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

**–ó–∞–¥–∞—á–∏:**

1. **–°–æ–∑–¥–∞—Ç—å —Å–∫—Ä–∏–ø—Ç –¥–ª—è eval retrieval:**
```bash
# –°–æ–∑–¥–∞–π—Ç–µ: eval/test_retrieval.py
```

```python
# eval/test_retrieval.py
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))

from src.retrieval_metrics import evaluate_retrieval_batch
from src.final_chain import create_final_hybrid_chain
import csv

def main():
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
    dataset = []
    with open("tests/dataset.csv", "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        dataset = list(reader)

    # –°–æ–∑–¥–∞–µ–º retrieval –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
    chain, retriever = create_final_hybrid_chain()

    # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –ø–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
    retrieved_docs_list = []
    for item in dataset:
        question = item["question"].replace('[cite_start]', '')
        docs = retriever.get_relevant_documents(question)

        # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º page_content –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è)
        doc_ids = [str(i) for i, _ in enumerate(docs)]  # —É–ø—Ä–æ—â–µ–Ω–Ω–æ
        retrieved_docs_list.append(doc_ids)

    # –î–ª—è –Ω–∞—á–∞–ª–∞ - —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ hit rate
    # (–ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç—Ä–µ–±—É–µ—Ç –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)
    print(f"‚úÖ Retrieval –æ—Ü–µ–Ω–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
    print(f"üìä –ò–∑–≤–ª–µ—á–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è {len(dataset)} –≤–æ–ø—Ä–æ—Å–æ–≤")
    print(f"–°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {sum(len(d) for d in retrieved_docs_list) / len(retrieved_docs_list):.1f}")

    # TODO: –î–æ–±–∞–≤–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ—Å–ª–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏

if __name__ == "__main__":
    main()
```

2. **–ó–∞–ø—É—Å—Ç–∏—Ç–µ:**
```bash
mkdir -p eval
python eval/test_retrieval.py
```

3. **–ê–Ω–Ω–æ—Ç–∏—Ä—É–π—Ç–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å (—á–∞—Å—Ç–∏—á–Ω–æ, –¥–ª—è –Ω–∞—á–∞–ª–∞):**
   - –í—ã–±–µ—Ä–∏—Ç–µ 10 –≤–æ–ø—Ä–æ—Å–æ–≤ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞
   - –î–ª—è –∫–∞–∂–¥–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –ø–æ—Å–º–æ—Ç—Ä–∏—Ç–µ, –∫–∞–∫–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã retriever –Ω–∞—à–µ–ª
   - –û—Ç–º–µ—Ç—å—Ç–µ, –∫–∞–∫–∏–µ –∏–∑ –Ω–∏—Ö –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã
   - –°–æ–∑–¥–∞–π—Ç–µ `tests/retrieval_sample.json`

---

### ‚úÖ –≠—Ç–∞–ø 3: –†–∞—Å—à–∏—Ä–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç –¥–æ 50 –≤–æ–ø—Ä–æ—Å–æ–≤ (3-5 –¥–Ω–µ–π)

**–¶–µ–ª—å:** –£–≤–µ–ª–∏—á–∏—Ç—å –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å eval

**–ó–∞–¥–∞—á–∏:**

1. **–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤:**
```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
mkdir -p scripts
python scripts/generate_questions.py
```

2. **–†—É—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞:**
```bash
# –û—Ç–∫—Ä–æ–π—Ç–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã
cat tests/dataset_extended.csv

# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ:
# - –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –≤–æ–ø—Ä–æ—Å–æ–≤
# - –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–æ–≤
# - –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
```

3. **–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤:**
```bash
# –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
cat tests/dataset.csv > tests/dataset_full.csv
tail -n +2 tests/dataset_extended.csv >> tests/dataset_full.csv

# –û–±–Ω–æ–≤–∏—Ç–µ run_ab_test.py
# DATASET_NAME = "golden-questions-full"
```

4. **–ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤ LangSmith:**
```python
from langsmith import Client

client = Client()

# –°–æ–∑–¥–∞–π—Ç–µ –Ω–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç –≤ LangSmith –∏–∑ dataset_full.csv
# (–∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ LangSmith UI –∏–ª–∏ API)
```

---

### ‚úÖ –≠—Ç–∞–ø 4: –î–æ–±–∞–≤–∏—Ç—å advanced generation –º–µ—Ç—Ä–∏–∫–∏ (2-3 –¥–Ω—è)

**–¶–µ–ª—å:** –î–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–æ–≤

**–ó–∞–¥–∞—á–∏:**

1. **–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ run_ab_test.py:**
```python
# –î–æ–±–∞–≤—å—Ç–µ –≤ run_ab_test.py
from src.advanced_generation_metrics import (
    evaluate_faithfulness,
    evaluate_answer_relevance,
    evaluate_citation_quality
)

# –°–æ–∑–¥–∞–π—Ç–µ custom evaluator
def advanced_evaluator(run, example):
    question = example.inputs.get("question")
    answer = run.outputs.get("output")
    context = run.outputs.get("context", "")  # –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω

    metrics = {}

    # Faithfulness
    faith_result = evaluate_faithfulness(question, context, answer, judge_llm)
    metrics.update(faith_result)

    # Answer relevance
    rel_result = evaluate_answer_relevance(question, answer, judge_llm)
    metrics.update(rel_result)

    # Citation quality
    cite_result = evaluate_citation_quality(answer, context, [])
    metrics.update(cite_result)

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π score
    return {
        "score": metrics.get("faithfulness_score", 0.0),
        "comment": f"Faith: {metrics.get('faithfulness_score'):.2f}, Rel: {metrics.get('answer_relevance_score'):.2f}"
    }

# –î–æ–±–∞–≤—å—Ç–µ –≤ evaluation_config
evaluation_config = RunEvalConfig(
    custom_evaluators=[check_correctness, advanced_evaluator],
    evaluators=["qa", "context_qa"],
    eval_llm=judge_llm,
)
```

2. **–ó–∞–ø—É—Å—Ç–∏—Ç–µ extended eval:**
```bash
python run_ab_test.py
```

---

### ‚úÖ –≠—Ç–∞–ø 5: –ù–∞—Å—Ç—Ä–æ–∏—Ç—å CI/CD (2-3 –¥–Ω—è)

**–¶–µ–ª—å:** –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π eval –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö

**–ó–∞–¥–∞—á–∏:**

1. **–°–æ–∑–¥–∞–π—Ç–µ GitHub Action:**
```yaml
# .github/workflows/evaluation.yml
name: Evaluation

on:
  pull_request:
  push:
    branches: [main, develop]
  workflow_dispatch:  # —Ä—É—á–Ω–æ–π –∑–∞–ø—É—Å–∫

jobs:
  evaluate:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Run evaluation
        env:
          GIGACHAT_CREDENTIALS: ${{ secrets.GIGACHAT_CREDENTIALS }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          LANGSMITH_API_KEY: ${{ secrets.LANGSMITH_API_KEY }}
        run: |
          python run_ab_test.py

      - name: Compare with baseline
        run: |
          python scripts/compare_metrics.py
```

2. **–°–æ–∑–¥–∞–π—Ç–µ —Å–∫—Ä–∏–ø—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è:**
```bash
# scripts/compare_metrics.py
# TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–µ–∫—É—â–∏—Ö –º–µ—Ç—Ä–∏–∫ —Å baseline
```

---

## üìä –î–∞—à–±–æ—Ä–¥ –º–µ—Ç—Ä–∏–∫

### –ß—Ç–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å:

1. **Correctness** (–≥–ª–∞–≤–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞)
   - –¶–µ–ª–µ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: > 8.0/10
   - –ö—Ä–∏—Ç–∏—á–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: < 6.0 (–∞–ª–µ—Ä—Ç!)

2. **Faithfulness** (–≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏)
   - –¶–µ–ª–µ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: > 0.9
   - –ö—Ä–∏—Ç–∏—á–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: < 0.7

3. **Answer Relevance**
   - –¶–µ–ª–µ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: > 0.85

4. **Retrieval Hit Rate @ 10**
   - –¶–µ–ª–µ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: > 0.9

5. **Latency (P95)**
   - –¶–µ–ª–µ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: < 10 —Å–µ–∫—É–Ω–¥

6. **Cost per query**
   - –¶–µ–ª–µ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: < $0.05

---

## üêõ Troubleshooting

### –ü—Ä–æ–±–ª–µ–º–∞: LangSmith –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
echo $LANGSMITH_API_KEY
echo $LANGSMITH_PROJECT

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ
export LANGSMITH_API_KEY="lsv2_..."
export LANGSMITH_TRACING_V2=true
```

### –ü—Ä–æ–±–ª–µ–º–∞: –ù–∏–∑–∫–∏–π correctness score
1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ quality of retrieval (–ø–æ–ª—É—á–µ–Ω—ã –ª–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã?)
2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–æ–º–ø—Ç—ã –≤ agents (RelevanceChecker, ResearchAgent)
3. –£–≤–µ–ª–∏—á—å—Ç–µ `VECTOR_SEARCH_K` (–ø–æ–ø—Ä–æ–±—É–π—Ç–µ 15-20)
4. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–∏–µ –≤–µ—Å–∞ hybrid retrieval

### –ü—Ä–æ–±–ª–µ–º–∞: –ì–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏ (–Ω–∏–∑–∫–∏–π faithfulness)
1. –£–∂–µ—Å—Ç–æ—á–∏—Ç–µ –ø—Ä–æ–º–ø—Ç –≤ ResearchAgent ("–∏—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –∫–æ–Ω—Ç–µ–∫—Å—Ç")
2. –î–æ–±–∞–≤—å—Ç–µ citation requirement –≤ –ø—Ä–æ–º–ø—Ç
3. –£–≤–µ–ª–∏—á—å—Ç–µ temperature = 0.0 (–¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Å—Ç–∏—á–Ω–æ—Å—Ç—å)

---

## üìà –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

–ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è Quick Start:

1. **–†–∞—Å—à–∏—Ä–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç –¥–æ 100+ –≤–æ–ø—Ä–æ—Å–æ–≤**
2. **–ù–∞—Å—Ç—Ä–æ–∏—Ç—å W&B –¥–ª—è experiment tracking**
3. **–î–æ–±–∞–≤–∏—Ç—å production –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥**
4. **–ü—Ä–æ–≤–µ—Å—Ç–∏ hyperparameter tuning**
5. **–ù–∞—Å—Ç—Ä–æ–∏—Ç—å drift detection**

---

## üìö –ü–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏

- [Roadmap –ø—Ä–æ–µ–∫—Ç–∞](../ROADMAP.md)
- [LangSmith Docs](https://docs.smith.langchain.com/)
- [RAGAS Framework](https://docs.ragas.io/)
- [Retrieval –º–µ—Ç—Ä–∏–∫–∏](./src/retrieval_metrics.py)
- [Advanced Generation –º–µ—Ç—Ä–∏–∫–∏](./src/advanced_generation_metrics.py)

---

**–í–æ–ø—Ä–æ—Å—ã?** –°–æ–∑–¥–∞–π—Ç–µ issue –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏.
